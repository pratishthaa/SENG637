**SENG 637 - Dependability and Reliability of Software Systems**

**Lab. Report #3 – Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group: 4      |
|-----------------|
| Student 1 Arpita Chowdhury                |   
| Student 2 Fadila Abdulai Hamid             |   
| Student 3 Kumkum Akter             |   
| Student 4 Niloofar Sharifisadr              |
| Student 5 Pratishtha Pratishtha |  


**Table of Contents**

[1 Introduction	1](#intro)

[2 Manual data-flow coverage calculations for X and Y methods](#man)

[3 A detailed description of the testing strategy for the new unit test](#testst)

[4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage](#hld)

[5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)](#det)

[6 Pros and Cons of coverage tools used and Metrics you report](#pcon)

[7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.](#diffe)

[8 A discussion on how the team work/effort was divided and managed](#team)

[9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab](#diff)

[10 Comments/feedback on the lab itself](#comm)


# 1 Introduction <a name="intro"></a>

Software testing is a critical component of the software development process, aiming to ensure the reliability, correctness, and robustness of software systems. In this assignment, our focus is on unit testing, specifically using JUnit, a popular testing framework in the Java ecosystem. Through this assignment, we delved into the principles of testing, with a particular emphasis on **white-box coverage criteria**, which help determine the adequacy of a test suite based on its coverage of the underlying code.

Our goal in this assignment is to write new test cases and utilize the test cases from the previous assignment to meet a predetermined code coverage. The `JFreeChart` package, which allows us to create charts in various ways, is the **system under test (SUT)**. It is an open-source Java framework available for free that calculates, creates, and displays charts. Numerous chart types are supported by this framework, such as histograms, pie charts, bar charts, line charts, and several others. The percentage of the source code that is covered while the test suite executes is the code coverage. JFreeChart makes it easy for developers to display professional charts in their applications. In Project 2, we created black-box test cases for ten distinct JFreeChart methods; five of them from the `Range class` and the other five from the `DataUtilities class`. 

Code coverage tools play a vital role in this process by providing insights into the extent to which the code is exercised by the test suite. Various coverage metrics, such as statement, branch, and condition coverages, aid in assessing the comprehensiveness of testing efforts. Additionally, we explored data-flow coverage criteria, such as DU pairs coverage, to deepen their understanding of how coverage tools work. In this assignment, we employ these test cases and test for their code coverage. We hope to achieve a minimum of 
  - 90% statement coverage.
  - 70% branch coverage.
  - 60%  method coverage.

For methods that we don't attain this defined code coverages, we have written new test cases to increase test coverage. For methods we obtain the minimum defined coverage, we have written more test cases for practice and improve ourselves at Software Testing.

In this report, throughout all sections, we will provide a detailed account of our testing strategy, including the selection of coverage metrics, the tools used for measuring coverage, and the challenges encountered during the testing process. We will discuss the advantages and limitations of different coverage tools, reflecting on their integration with IDEs, user-friendliness, and effectiveness in identifying gaps in test coverage apart from manual data flow coverage.

# 2 Manual data-flow coverage calculations for X and Y methods <a name="man"></a>

Text…

# 3 A detailed description of the testing strategy for the new unit test <a name="testst"></a>

Text…

# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage <a name="hld"></a>

Text…

# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice) <a name="det"></a>

Text…

# 6 Pros and Cons of coverage tools used and Metrics you report <a name="pcon"></a>

Text…

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation. <a name="diffe"></a>

Text…

# 8 A discussion on how the team work/effort was divided and managed <a name="team"></a>

Text…

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab <a name="diff"></a>

Text…

# 10 Comments/feedback on the lab itself <a name="comm"></a>

Text…

